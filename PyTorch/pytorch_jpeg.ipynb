{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import  DataLoader, Dataset\n",
    "import torchvision\n",
    "\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms as T\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_directml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/joey5/OneDrive/KU/Fourth Year/AppML/Final_Project/fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting pixel data from pixel column\n",
    "# convert it to integer\n",
    "# drop original pixel column\n",
    "# add all pixels as individual column\n",
    "\n",
    "pixels = []\n",
    "\n",
    "for pix in data.pixels:\n",
    "    values = [int(i) for i in pix.split()]\n",
    "    pixels.append(values)\n",
    "\n",
    "pixels = np.array(pixels)\n",
    "\n",
    "# rescaling pixel values\n",
    "pixels = pixels/255.0\n",
    "\n",
    "\n",
    "data.drop(columns=['pixels'], axis=1, inplace=True)\n",
    "\n",
    "pix_cols = [] # for keeping track of column names\n",
    "\n",
    "# add each pixel value as a column\n",
    "for i in range(pixels.shape[1]):\n",
    "    name = f'pixel_{i}'\n",
    "    pix_cols.append(name)\n",
    "    data[name] = pixels[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28709, 2306), (3589, 2306))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data[data['Usage'] == 'Training']\n",
    "test_data = data[data['Usage'] == 'PublicTest']\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FERDataset(Dataset):\n",
    "    '''\n",
    "        Parse raw data to form a Dataset of (X, y).\n",
    "    '''\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.path = data_path\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = int(row['emotion'])\n",
    "        img = np.copy(row[pix_cols].values.reshape(48, 48))\n",
    "        img.setflags(write=True)\n",
    "\n",
    "        if self.transform:\n",
    "            img = Image.fromarray(img)\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = self.tensor_transform(img)\n",
    "\n",
    "        return img, img_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FERDataset(Dataset):\n",
    "    '''\n",
    "        Parse raw data to form a Dataset of (X, y).\n",
    "    '''\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.tensor_transform = T.ToTensor()\n",
    "        # self.tensor_transform = \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = int(row['emotion'])\n",
    "        img = np.copy(row[pix_cols].values.reshape(48, 48))\n",
    "        img.setflags(write=True)\n",
    "\n",
    "        if self.transform:\n",
    "            img = Image.fromarray(img)\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = self.tensor_transform(img)\n",
    "\n",
    "        return img, img_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    elif torch_directml.is_available():\n",
    "        return torch_directml.device()\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='privateuseone', index=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FERDataset(train_data)\n",
    "test_dataset = FERDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be used for any Image Classification task\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        # loss = F.nll_loss(outputs, labels) # Convert for problem at hand\n",
    "        acc = accuracy(outputs, labels)\n",
    "        return {'loss': loss, 'acc': acc.detach()}\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc.detach()}\n",
    "        \n",
    "    def get_metrics_epoch_end(self, outputs, validation=True):\n",
    "        if validation:\n",
    "            loss_ = 'val_loss'\n",
    "            acc_ = 'val_acc'\n",
    "        else:\n",
    "            loss_ = 'loss'\n",
    "            acc_ = 'acc'\n",
    "\n",
    "        batch_losses = [x[f'{loss_}'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   \n",
    "        batch_accs = [x[f'{acc_}'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      \n",
    "        return {f'{loss_}': epoch_loss.detach().item(), f'{acc_}': epoch_acc.detach().item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result, num_epochs):\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs} -> lr: {result['lrs'][-1]:.5f} loss: {result['loss']:.4f}, acc: {result['acc']:.4f}, val_loss: {result['val_loss']:.4f}, val_acc: {result['val_acc']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionRecognition(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2), # output: 16 x 24 x 24\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 12 x 12\n",
    "\n",
    "            # nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            # # nn.ReLU(),\n",
    "            # # nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            # nn.MaxPool2d(2, 2), # output: 128 x 6 x 6\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(64*6*6, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 7))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.network}\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        summary(self.network, (1, 48, 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_transformations() -> (object, object):\n",
    "    '''\n",
    "        Return transformations to be applied.\n",
    "        Input:\n",
    "            None\n",
    "        Output:\n",
    "            train_tfms: transformations to be applied on the training set\n",
    "            valid_tfms: transformations to be applied on the validation or test set\n",
    "    '''\n",
    "\n",
    "    train_trans = [      \n",
    "        T.RandomCrop(48, padding=4, padding_mode='reflect'),     \n",
    "        T.RandomRotation(15),\n",
    "        T.RandomAffine(\n",
    "            degrees=0,\n",
    "            translate=(0.01, 0.12),\n",
    "            shear=(0.01, 0.03),\n",
    "        ),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "    ]\n",
    "\n",
    "    val_trans = [\n",
    "        T.ToTensor(), \n",
    "    ]\n",
    "\n",
    "    train_transformations = T.Compose(train_trans)\n",
    "    valid_tfms = T.Compose(val_trans)\n",
    "\n",
    "    return train_transformations, valid_tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_dataset(dataframe: object, transformation: bool=False) -> (object, object):\n",
    "    '''\n",
    "        Returns an object on FERDataset class\n",
    "        Input:\n",
    "            dataframe: object -> DataFrame object containing the whole data\n",
    "            transformation: bool [optional] ->  Apply transformations\n",
    "    '''\n",
    "\n",
    "    # extracts rows specific to Training, PublicTest\n",
    "    dataframe = dataframe.loc[dataframe.Usage.isin(['Training', 'PublicTest'])]\n",
    "    # drop Usage column as it's no longer needed    \n",
    "    dataframe = dataframe.drop('Usage', axis=1)\n",
    "\n",
    "    # split dataset into training and validation set\n",
    "    np.random.seed(42)  \n",
    "    msk = np.random.rand(len(dataframe)) < 0.8\n",
    "\n",
    "    train_df = dataframe[msk].reset_index()\n",
    "    val_df = dataframe[~msk].reset_index()\n",
    "\n",
    "    # get transformations\n",
    "    if transformation:\n",
    "        train_tfms, valid_tfms = image_transformations()\n",
    "    else:\n",
    "        train_tfms, valid_tfms = None, None\n",
    "\n",
    "    # fetch dataset\n",
    "    train_ds = FERDataset(dataframe, transform=train_tfms)\n",
    "    val_ds = FERDataset(dataframe, transform=valid_tfms)\n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_dataloader(dataframe: object, transformation=False, batch_size: int=32) -> (object, object):\n",
    "    '''\n",
    "        Returns train and test dataloaders.\n",
    "        Input:\n",
    "            dataframe: dataset DataFrame object\n",
    "            batch_size: [optional] int\n",
    "        Output:\n",
    "            train_dl: train dataloader object\n",
    "            valid_dl: validation dataloader object\n",
    "    '''\n",
    "    # fetech train and validation dataset\n",
    "    train_ds, valid_ds = get_train_dataset(dataframe, transformation=transformation)\n",
    "    \n",
    "    train_dl = DataLoader(train_ds, batch_size, shuffle=True, \n",
    "                     num_workers=3, pin_memory=True)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size*2, \n",
    "                    num_workers=2, pin_memory=True)\n",
    "    \n",
    "    return train_dl, valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_dataloader(dataframe: object, batch_size: int=128) -> object:\n",
    "    '''\n",
    "        Returns test set dataloaders.\n",
    "        Input:\n",
    "            dataframe: dataset DataFrame object\n",
    "            batch_size: [optional] int\n",
    "        Output:\n",
    "            test_dl: test dataloader object\n",
    "    '''\n",
    "    # extracts rows specific to PrivateTest\n",
    "    test_df = dataframe.loc[data.Usage.isin(['PrivateTest'])]\n",
    "\n",
    "    # drop Usage column as it's no longer needed\n",
    "    test_df = test_df.drop('Usage', axis=1)\n",
    "\n",
    "    # get transformations same as validation set\n",
    "    _, valid_tfms = image_transformations()\n",
    "    \n",
    "    test_dataset = FERDataset(test_df, transform=valid_tfms)\n",
    "    test_dl = DataLoader(test_dataset, batch_size, num_workers=3 , pin_memory=True)\n",
    "\n",
    "    # move loader to GPU (class defined ahead)\n",
    "    test_dl = DeviceDataLoader(test_dl, device)\n",
    "    return test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model: object, val_loader: object) -> dict:\n",
    "    '''\n",
    "        Evaluate model on the validation set\n",
    "        Input:\n",
    "            model: training model object\n",
    "            val_loder: validation data loader object\n",
    "        Output:\n",
    "            validation metrics\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.get_metrics_epoch_end(outputs=outputs, validation=True)\n",
    "\n",
    "\n",
    "def get_lr(optimizer: object) -> float:\n",
    "    ''' Returns current learning rate'''\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "\n",
    "def fit_model(model_name: str,\n",
    "              model: object, \n",
    "              epochs: int, \n",
    "              max_lr: float, \n",
    "              train_loader: object, \n",
    "              val_loader: object,\n",
    "              weight_decay: float=0, \n",
    "              grad_clip: float=None, \n",
    "              opt_func: object=torch.optim.SGD):\n",
    "    '''\n",
    "        This function is responsible for training our model.\n",
    "        We use a One Cycle learning rate policy to update our learning rate \n",
    "        with each epoch.\n",
    "        The best model is saved during each epoch.\n",
    "        Input:\n",
    "            model_name: str \n",
    "            model: object\n",
    "            epochs: int -> Max epochs\n",
    "            max_lr: float -> Maximum allowed learning rate during learning\n",
    "            train_loader: training set data loader\n",
    "            val_loader: validation set data loader\n",
    "            weight_decay: float -> value to decrease weights during training of each batch\n",
    "            grad_clip: float -> maximum allowed gradient value\n",
    "            opt_func: optimzer object\n",
    "        Output:\n",
    "            history: list of metrics\n",
    "    '''\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    BEST_VAL_SCORE = 0.0 # for keeping track of best model score\n",
    "    history = []\n",
    "\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, max_lr=max_lr,\n",
    "                                                    epochs=epochs, \n",
    "                                                    steps_per_epoch=len(train_loader))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_history = []\n",
    "        lrs = []\n",
    "\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        for batch in tqdm(train_loader, ascii=True, desc=f'Epoch: {epoch+1}/{epochs}'):\n",
    "            info = model.training_step(batch)\n",
    "            loss = info['loss']\n",
    "            # contains batch loss and acc for training phase\n",
    "            train_history.append(info)\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            if grad_clip:\n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "        train_result = model.get_metrics_epoch_end(train_history, validation=False)\n",
    "        val_result = evaluate(model, val_loader)\n",
    "        result = {**train_result, **val_result}\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result, epochs)\n",
    "\n",
    "        # Save the best model\n",
    "        if result['val_acc'] > BEST_VAL_SCORE:\n",
    "            BEST_VAL_SCORE = result['val_acc']\n",
    "            save_name = f\"{model_name}_epoch-{epoch+1}_score-{round(result['val_acc'], 4)}.pth\"\n",
    "            !rm -f '{model_name}'_*\n",
    "            torch.save(model.state_dict(), save_name)\n",
    "\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to fetch test dataset and generate submission file for best model\n",
    "\n",
    "def load_best(model_name: str) -> object:\n",
    "    '''Returns the best model'''\n",
    "\n",
    "    # get model definition\n",
    "    best_model = models[model_name]\n",
    "\n",
    "    # load trained weights\n",
    "    path = r\"./\"\n",
    "    file_path = ''\n",
    "    \n",
    "    for i in os.listdir(path):\n",
    "        if os.path.isfile(os.path.join(path,i)) and i.startswith(f'{model_name}'):\n",
    "            file_path = os.path.join(path, i)\n",
    "            \n",
    "    print(f\"Loaded model: {file_path[2:]} weights.\")\n",
    "    best_model.load_state_dict(torch.load(file_path))\n",
    "\n",
    "    # move model to gpu\n",
    "    best_model = to_device(best_model, device)\n",
    "    return best_model   \n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_prediction(model_name: str) -> None:\n",
    "    '''Generate prediction on the test set'''\n",
    "\n",
    "    # load test dataset\n",
    "    test_dl = get_test_dataloader(data)\n",
    "    \n",
    "    # load model\n",
    "    model = load_best(model_name)\n",
    "\n",
    "    # clear cuda cache\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # generate prediction using the validation step method defined in Base class\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        outputs = [model.validation_step(batch) for batch in test_dl]\n",
    "        metrics = model.get_metrics_epoch_end(outputs=outputs, validation=True)\n",
    "\n",
    "    print(f\"Test Scores:\\n Loss: {round(metrics['val_loss'], 3)}, Accuracy: {round(metrics['val_acc'], 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_to_end(model_name: str, parameters: dict=None) -> dict:\n",
    "    '''\n",
    "        A simple function end-to-end training and testing on the selected model.\n",
    "        Inputs:\n",
    "            model_name: str -> chosen model name\n",
    "            parameters: dict -> dictionary of hyperparameters for the model\n",
    "        Outputs:\n",
    "            history: dict -> dictionary containing model metrics(loss, score, lr)\n",
    "\n",
    "    '''\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # hyperparameters\n",
    "    BATCH_SIZE = 1 # batch_sizes[model_name]\n",
    "    epochs = parameters[\"epochs\"]\n",
    "    max_lr = parameters[\"max_lr\"]\n",
    "    weight_decay = parameters[\"weight_decay\"]\n",
    "    grad_clip = parameters[\"grad_clip\"]\n",
    "    opt_func = parameters[\"opt_func\"]\n",
    "\n",
    "    # get transformed dataset\n",
    "    train_dl, valid_dl = get_train_dataloader(data, batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Print train batch input shape and labels:\n",
    "    for xb, yb in train_dl:\n",
    "        print('train batch shape:', xb.shape)\n",
    "        print('train batch labels:', yb)\n",
    "        plt.imshow(xb[0].permute(1, 2, 0))\n",
    "        plt.show()\n",
    "        break\n",
    "    return\n",
    "    # move dataset to use GPU\n",
    "    # train_dl = DeviceDataLoader(train_dl, device)\n",
    "    # valid_dl = DeviceDataLoader(valid_dl, device)\n",
    "\n",
    "    # get model\n",
    "    model = models[model_name]\n",
    "\n",
    "    # move model to GPU\n",
    "    model = to_device(model, device)\n",
    "    \n",
    "    # train model\n",
    "    history = fit_model(\n",
    "                model_name,\n",
    "                model, \n",
    "                epochs, \n",
    "                max_lr, \n",
    "                train_dl, \n",
    "                valid_dl,\n",
    "                weight_decay, \n",
    "                grad_clip, \n",
    "                opt_func\n",
    "            )\n",
    "\n",
    "    # cleaning\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # generate predictions\n",
    "    print(\"Generating predictions on the Test set\")\n",
    "    generate_prediction(model_name)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters = {\n",
    "    \"epochs\": 2,\n",
    "    \"max_lr\": 0.01,\n",
    "    \"weight_decay\": 0.1,\n",
    "    \"grad_clip\": 1e-4,\n",
    "    \"opt_func\": torch.optim.SGD,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"emotion_recognition\": EmotionRecognition()\n",
    "}\n",
    "\n",
    "dataset = data\n",
    "\n",
    "history = end_to_end(\"emotion_recognition\", training_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
