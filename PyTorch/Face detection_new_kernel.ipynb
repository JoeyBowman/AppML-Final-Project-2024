{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch as torch\n",
    "import torchvision as tv\n",
    "from functools import partial\n",
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import fsspec\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import torchvision.transforms as transforms\n",
    "import pyarrow.fs\n",
    "import ray\n",
    "from ray import tune\n",
    "import ray.train as train\n",
    "from ray.train import Checkpoint, get_checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import ray.cloudpickle as pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        # Assuming a structure where each class has its own subdirectory\n",
    "        for label, class_dir in enumerate(os.listdir(self.data_dir)):\n",
    "            class_path = os.path.join(self.data_dir, class_dir)\n",
    "            for count, img_name in enumerate(os.listdir(class_path)):\n",
    "                if count > 700:\n",
    "                    break\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                self.images.append(img_path)\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_custom_data(data_dir=\"./data\", batch_size=32):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomAffine(\n",
    "            degrees=0,\n",
    "            translate=(0.01, 0.12),\n",
    "            shear=(0.01, 0.03),\n",
    "        ),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5))\n",
    "    ])\n",
    "\n",
    "    train_dir = f\"{data_dir}/train\"\n",
    "    test_dir = f\"{data_dir}/test\"\n",
    "    \n",
    "    trainset = EmotionDataset(data_dir=train_dir, transform=transform)\n",
    "    testset = EmotionDataset(data_dir=test_dir, transform=transform)\n",
    "\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be used for any Image Classification task\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        # loss = F.nll_loss(outputs, labels) # Convert for problem at hand\n",
    "        acc = accuracy(outputs, labels)\n",
    "        return {'loss': loss, 'acc': acc.detach()}\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc.detach()}\n",
    "        \n",
    "    def get_metrics_epoch_end(self, outputs, validation=True):\n",
    "        if validation:\n",
    "            loss_ = 'val_loss'\n",
    "            acc_ = 'val_acc'\n",
    "        else:\n",
    "            loss_ = 'loss'\n",
    "            acc_ = 'acc'\n",
    "\n",
    "        batch_losses = [x[f'{loss_}'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   \n",
    "        batch_accs = [x[f'{acc_}'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      \n",
    "        return {f'{loss_}': epoch_loss.detach().item(), f'{acc_}': epoch_acc.detach().item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result, num_epochs):\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs} -> lr: {result['lrs'][-1]:.5f} loss: {result['loss']:.4f}, acc: {result['acc']:.4f}, val_loss: {result['val_loss']:.4f}, val_acc: {result['val_acc']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionRecognition(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2), # output: 16 x 24 x 24\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 12 x 12\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 6 x 6\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(128*6*6, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 7))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.network}\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        summary(self.network, (1, 48, 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model: object, val_loader: object) -> dict:\n",
    "    '''\n",
    "        Evaluate model on the validation set\n",
    "        Input:\n",
    "            model: training model object\n",
    "            val_loder: validation data loader object\n",
    "        Output:\n",
    "            validation metrics\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.get_metrics_epoch_end(outputs=outputs, validation=True)\n",
    "\n",
    "\n",
    "def get_lr(optimizer: object) -> float:\n",
    "    ''' Returns current learning rate'''\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "\n",
    "def fit_model(model: object, \n",
    "              epochs: int, \n",
    "              lr: float, \n",
    "              train_loader: object, \n",
    "              val_loader: object,\n",
    "              weight_decay: float=0, \n",
    "              grad_clip: float=None, \n",
    "              opt_func: object=torch.optim.SGD):\n",
    "    '''\n",
    "        This function is responsible for training our model.\n",
    "        We use a One Cycle learning rate policy to update our learning rate \n",
    "        with each epoch.\n",
    "        The best model is saved during each epoch.\n",
    "        Input:\n",
    "            model_name: str \n",
    "            model: object\n",
    "            epochs: int -> Max epochs\n",
    "            max_lr: float -> Maximum allowed learning rate during learning\n",
    "            train_loader: training set data loader\n",
    "            val_loader: validation set data loader\n",
    "            weight_decay: float -> value to decrease weights during training of each batch\n",
    "            grad_clip: float -> maximum allowed gradient value\n",
    "            opt_func: optimzer object\n",
    "        Output:\n",
    "            history: list of metrics\n",
    "    '''\n",
    "\n",
    "    model_name = \"test_model\"\n",
    "    BEST_VAL_SCORE = 0.0 # for keeping track of best model score\n",
    "    history = []\n",
    "\n",
    "    optimizer = opt_func(model.parameters(), lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, max_lr=lr,\n",
    "                                                    epochs=epochs, \n",
    "                                                    steps_per_epoch=len(train_loader))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_history = []\n",
    "        lrs = []\n",
    "\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        for batch in tqdm(train_loader, ascii=True, desc=f'Epoch: {epoch+1}/{epochs}'):\n",
    "            info = model.training_step(batch)\n",
    "            loss = info['loss']\n",
    "            # contains batch loss and acc for training phase\n",
    "            train_history.append(info)\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            if grad_clip:\n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "        train_result = model.get_metrics_epoch_end(train_history, validation=False)\n",
    "        val_result = evaluate(model, val_loader)\n",
    "        result = {**train_result, **val_result}\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result, epochs)\n",
    "\n",
    "        # Save the best model\n",
    "        if result['val_acc'] > BEST_VAL_SCORE:\n",
    "            BEST_VAL_SCORE = result['val_acc']\n",
    "            save_name = f\"{model_name}_epoch-{epoch+1}_score-{round(result['val_acc'], 4)}.pth\"\n",
    "            !rm -f '{model_name}'_*\n",
    "            torch.save(model.state_dict(), save_name)\n",
    "\n",
    "        history.append(result)\n",
    "    return history\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_prediction(model, data) -> None:\n",
    "    '''Generate prediction on the test set'''\n",
    "\n",
    "    # load test dataset\n",
    "    test_dl = DataLoader(data, batch_size=32, shuffle=True)\n",
    "\n",
    "    # generate prediction using the validation step method defined in Base class\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        outputs = [model.validation_step(batch) for batch in test_dl]\n",
    "        metrics = model.get_metrics_epoch_end(outputs=outputs, validation=True)\n",
    "\n",
    "    print(f\"Test Scores:\\n Loss: {round(metrics['val_loss'], 3)}, Accuracy: {round(metrics['val_acc'], 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_to_end(trainset, testset, parameters: dict=None) -> dict:\n",
    "    '''\n",
    "        A simple function end-to-end training and testing on the selected model.\n",
    "        Inputs:\n",
    "            model_name: str -> chosen model name\n",
    "            parameters: dict -> dictionary of hyperparameters for the model\n",
    "        Outputs:\n",
    "            history: dict -> dictionary containing model metrics(loss, score, lr)\n",
    "\n",
    "    '''\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # hyperparameters\n",
    "    BATCH_SIZE = parameters[\"batch_size\"]\n",
    "    epochs = parameters[\"epochs\"]\n",
    "    max_lr = parameters[\"max_lr\"]\n",
    "    weight_decay = parameters[\"weight_decay\"]\n",
    "    grad_clip = parameters[\"grad_clip\"]\n",
    "    opt_func = parameters[\"opt_func\"]\n",
    "\n",
    "    # get transformed dataset\n",
    "    train_dl = DataLoader(trainset, BATCH_SIZE, shuffle=True)\n",
    "    valid_dl = DataLoader(testset, BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    # # Print batch img shape, label and plot image:\n",
    "    # img, label = next(iter(train_dl))\n",
    "    # print(f\"Batch Shape: {img.shape}\")\n",
    "    # print(f\"Label: {label}\")\n",
    "    # plt.imshow(img[0].numpy().squeeze(), cmap='gray')\n",
    "    # plt.show()\n",
    "\n",
    "    # get model\n",
    "    model = EmotionRecognition()\n",
    "\n",
    "    # move model to GPU\n",
    "    # model = to_device(model, device)\n",
    "    \n",
    "    # train model\n",
    "    history = fit_model(\n",
    "                model, \n",
    "                epochs, \n",
    "                max_lr, \n",
    "                train_dl, \n",
    "                valid_dl,\n",
    "                weight_decay, \n",
    "                grad_clip, \n",
    "                opt_func\n",
    "            )\n",
    "\n",
    "    # cleaning\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # generate predictions\n",
    "    print(\"Generating predictions on the Test set\")\n",
    "    generate_prediction(model, testset)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters = {\n",
    "    \"epochs\": 10,\n",
    "    \"max_lr\": 0.005,\n",
    "    \"weight_decay\": 0.1,\n",
    "    \"grad_clip\": 1e-4,\n",
    "    \"opt_func\": torch.optim.SGD,\n",
    "    \"batch_size\": 32\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = load_custom_data(data_dir=\"C:/Users/joey5/OneDrive/KU/Fourth Year/AppML/Final_Project\", batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10:   0%|          | 0/898 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10: 100%|##########| 898/898 [02:43<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 -> lr: 0.00140 loss: 1.9187, acc: 0.2370, val_loss: 1.9277, val_acc: 0.2470\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "Epoch: 2/10: 100%|##########| 898/898 [02:30<00:00,  5.98it/s]\n",
      "Epoch: 3/10:   0%|          | 0/898 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10 -> lr: 0.00380 loss: 1.9415, acc: 0.2516, val_loss: 1.9456, val_acc: 0.2467\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10: 100%|##########| 898/898 [02:30<00:00,  5.97it/s]\n",
      "Epoch: 4/10:   0%|          | 1/898 [00:00<02:02,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10 -> lr: 0.00500 loss: 1.9456, acc: 0.2511, val_loss: 1.9456, val_acc: 0.2467\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10: 100%|##########| 898/898 [02:35<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10 -> lr: 0.00475 loss: 1.9456, acc: 0.2515, val_loss: 1.9456, val_acc: 0.2473\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "Epoch: 5/10: 100%|##########| 898/898 [02:20<00:00,  6.38it/s]\n",
      "Epoch: 6/10:   0%|          | 1/898 [00:00<02:11,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10 -> lr: 0.00406 loss: 1.9456, acc: 0.2513, val_loss: 1.9456, val_acc: 0.2467\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10: 100%|##########| 898/898 [02:11<00:00,  6.81it/s]\n",
      "Epoch: 7/10:   0%|          | 1/898 [00:00<02:10,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10 -> lr: 0.00306 loss: 1.9456, acc: 0.2511, val_loss: 1.9456, val_acc: 0.2473\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10: 100%|##########| 898/898 [02:03<00:00,  7.28it/s]\n",
      "Epoch: 8/10:   0%|          | 1/898 [00:00<01:59,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10 -> lr: 0.00194 loss: 1.9456, acc: 0.2513, val_loss: 1.9456, val_acc: 0.2470\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10: 100%|##########| 898/898 [01:57<00:00,  7.61it/s]\n",
      "Epoch: 9/10:   0%|          | 1/898 [00:00<01:46,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10 -> lr: 0.00094 loss: 1.9456, acc: 0.2513, val_loss: 1.9456, val_acc: 0.2473\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10: 100%|##########| 898/898 [01:59<00:00,  7.49it/s]\n",
      "Epoch: 10/10:   0%|          | 1/898 [00:00<01:51,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10 -> lr: 0.00025 loss: 1.9456, acc: 0.2511, val_loss: 1.9456, val_acc: 0.2470\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10: 100%|##########| 898/898 [02:14<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10 -> lr: 0.00000 loss: 1.9456, acc: 0.2513, val_loss: 1.9456, val_acc: 0.2470\n",
      "\n",
      "Generating predictions on the Test set\n",
      "Test Scores:\n",
      " Loss: 1.946, Accuracy: 0.248\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = end_to_end(trainset, testset, training_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the confusion matrix\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
